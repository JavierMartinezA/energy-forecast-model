# Proyecto: Predicci√≥n de Generaci√≥n de Energ√≠a Solar Multi-Planta

## üìã Descripci√≥n

Sistema automatizado de predicci√≥n de generaci√≥n de energ√≠a solar para **m√∫ltiples plantas fotovoltaicas**, usando modelos h√≠bridos avanzados de Deep Learning. Predice hasta **48 horas de generaci√≥n** usando datos hist√≥ricos optimizables (11h-24h), alineado con los requerimientos del **Coordinador El√©ctrico Nacional (CEN)** de Chile.

### üß† Arquitecturas Implementadas

1. **Dual-Stream (BiLSTM + CNN 1D)**: Arquitectura base de producci√≥n - 2 entradas paralelas
2. **Tri-Stream con Gating Multiplicativo**: Arquitectura avanzada - 3 entradas con modelado expl√≠cito del estado operativo

**Benchmark exhaustivo**: 41 modelos entrenados y evaluados (4 plantas √ó 2 arquitecturas √ó 2 ventanas hist√≥ricas)

### üéØ Objetivo

Predecir la generaci√≥n normalizada de energ√≠a solar para las **pr√≥ximas 48 horas** (day-ahead + intraday) utilizando:
- **Entrada 1 (Hist√≥rico)**: Ventana optimizable de datos pasados (11h-24h recomendado) con generaci√≥n + variables meteorol√≥gicas
- **Entrada 2 (Pron√≥stico Meteorol√≥gico)**: 48 horas futuras de variables meteorol√≥gicas conocidas
- **Entrada 3 (Estado Operativo - Solo Tri-Stream)**: Variables binarias de estado (feriados, mantenimientos)
- **Salida**: 48 valores de generaci√≥n futura normalizada (0-1)

**Innovaci√≥n clave**: Sistema multi-arquitectura que permite elegir entre velocidad (Dual-Stream) o precisi√≥n (Tri-Stream) seg√∫n necesidad.

### üè≠ Plantas Soportadas

El sistema est√° dise√±ado para funcionar con **cualquier planta solar** configurando simplemente:
- `ID_PLANTA`: Identificador √∫nico de la planta
- `FECHA_INICIO` y `FECHA_FIN`: Per√≠odo de datos disponible por planta

**Plantas validadas con modelos entrenados** (dataset 2013-2015):
- **239**: SDGX01 (1.28 MW) - Per√≠odo: 2013-08-08 a 2015-08-08 - 17 modelos entrenados
- **305**: Lalackama II (0.79 MW) - Per√≠odo: 2013-08-08 a 2015-08-08 - 8 modelos entrenados
- **309**: Tambo Real (2.94 MW) - Per√≠odo: 2013-01-01 a 2015-01-01 - 8 modelos entrenados
- **346**: Esperanza (2.88 MW) - Per√≠odo: 2014-01-01 a 2015-12-20 - 8 modelos entrenados

El pipeline se adapta autom√°ticamente a:
- ‚úÖ Diferentes capacidades instaladas (normalizaci√≥n por potencia m√°xima)
- ‚úÖ Diferentes patrones meteorol√≥gicos (ubicaciones geogr√°ficas)
- ‚úÖ Diferentes per√≠odos hist√≥ricos disponibles
- ‚úÖ Caracter√≠sticas operativas espec√≠ficas de cada planta

**Total evaluado**: 41 configuraciones de modelos a trav√©s de las 4 plantas.

---

## üèóÔ∏è Estructura del Proyecto

```
project-solar-power/
‚îú‚îÄ‚îÄ data/                                # Datos en diferentes etapas
‚îÇ   ‚îú‚îÄ‚îÄ 01_raw/                          # Datos originales sin procesar
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generacion_solar_*.json      # Datos de generaci√≥n solar (API CEN)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Datos2013-2015_Planta*.csv   # Datos meteorol√≥gicos por planta
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ centrales_solares_pre_2017.json  # Metadata de plantas
‚îÇ   ‚îú‚îÄ‚îÄ 02_interim/                      # Datos combinados y normalizados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ InterimCombinado_*.csv       # Solar + Meteo normalizados
‚îÇ   ‚îî‚îÄ‚îÄ 03_processed/                    # Datos finales con features
‚îÇ       ‚îî‚îÄ‚îÄ DatosCombinados_*.csv        # Listo para modelado
‚îÇ
‚îú‚îÄ‚îÄ figures/                             # Gr√°ficos y m√©tricas de resultados
‚îÇ   ‚îú‚îÄ‚îÄ dual_stream_lstm_cnn_*_history.csv    # Historial entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ training_summary.csv              # Resumen de todos los modelos
‚îÇ   ‚îú‚îÄ‚îÄ predicciones_ejemplos.png         # Comparaci√≥n predicci√≥n vs real
‚îÇ   ‚îú‚îÄ‚îÄ error_por_hora.png                # MAE por hora de predicci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ training_history.png              # Curvas de entrenamiento
‚îÇ
‚îú‚îÄ‚îÄ models/                              # Modelos entrenados (.keras)
‚îÇ   ‚îú‚îÄ‚îÄ dual_stream_lstm_cnn_239_24h_48h.keras  # Modelo Dual-Stream planta 239
‚îÇ   ‚îú‚îÄ‚îÄ dual_stream_lstm_cnn_309_11h_48h.keras  # Modelo Dual-Stream planta 309
‚îÇ   ‚îú‚îÄ‚îÄ dual_stream_lstm_cnn_346_24h_48h.keras  # Modelo Dual-Stream planta 346
‚îÇ   ‚îî‚îÄ‚îÄ tri_stream_gating_239_24h_48h.keras     # Modelo Tri-Stream planta 239
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                           # Jupyter notebooks refactorizados (reporte t√©cnico)
‚îÇ   ‚îú‚îÄ‚îÄ exploracion_datos.ipynb          # EDA - Key Visual Insights (serie temporal, heatmaps, correlaci√≥n, ACF/PACF, outliers)
‚îÇ   ‚îú‚îÄ‚îÄ exploracion_modelos.ipynb        # Evaluaci√≥n - M√©tricas, curvas entrenamiento, predicciones 48h, residuales
‚îÇ   ‚îî‚îÄ‚îÄ exploracion_resultados.ipynb     # Comparaci√≥n Multi-Modelo - Rankings, eficiencia, heatmaps (Dual/Tri √ó 4 plantas √ó 2 ventanas)
‚îÇ
‚îú‚îÄ‚îÄ src/                                 # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ data/                            # Scripts de procesamiento de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extract.py                   # [OPCIONAL] Descarga datos de API CEN
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ make_dataset.py              # Combina y normaliza datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fix_shadow_cloud.py          # Correcci√≥n de datos espec√≠ficos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ubicacion.py                 # Info geogr√°fica de plantas
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ features/                        # Ingenier√≠a de caracter√≠sticas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py            # Crea features temporales c√≠clicas
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ models/                          # Modelos y predicciones
‚îÇ       ‚îú‚îÄ‚îÄ windowing_utils.py           # Creaci√≥n de ventanas temporales (Dual/Tri-Stream)
‚îÇ       ‚îú‚îÄ‚îÄ train_model.py               # Entrenamiento Dual-Stream
‚îÇ       ‚îú‚îÄ‚îÄ train_alternativo.py         # Entrenamiento Tri-Stream con Gating
‚îÇ       ‚îú‚îÄ‚îÄ predict_model.py             # Evaluaci√≥n y visualizaci√≥n
‚îÇ       ‚îî‚îÄ‚îÄ Trainmodelo_multiplanta.py   # [Reservado] Entrenamiento batch
‚îÇ
‚îú‚îÄ‚îÄ run.py                               # Orquestador del pipeline completo
‚îú‚îÄ‚îÄ validar_splits.py                    # Validaci√≥n de splits temporales
‚îú‚îÄ‚îÄ verificar_datos.py                   # Verificaci√≥n de integridad de datos
‚îú‚îÄ‚îÄ requirements.txt                     # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                            # Este archivo
```

---

## üîÑ Flujo del Pipeline

### Pipeline Completo (Orden de Ejecuci√≥n)

```mermaid
graph TD
    A[01_raw/: Datos Crudos] --> B[make_dataset.py]
    B --> C[02_interim/: Datos Normalizados]
    C --> D[build_features.py]
    D --> E[03_processed/: Features Finales]
    E --> F[train_model.py]
    F --> G[models/: Modelo Entrenado]
    E --> H[predict_model.py]
    G --> H
    H --> I[figures/: Visualizaciones]
```

### 1Ô∏è‚É£ **Procesamiento de Datos** (`src/data/make_dataset.py`)

**Entrada**: 
- `data/01_raw/generacion_solar_*.json` (API CEN)
- `data/01_raw/Datos2013-2015_*.csv` (Meteorolog√≠a)

**Proceso**:
1. Carga datos de generaci√≥n solar
2. Carga datos meteorol√≥gicos
3. Combina por timestamp (inner join)
4. Normaliza variables meteorol√≥gicas con MinMaxScaler

**Salida**: 
- `data/02_interim/InterimCombinado_*.csv`

**Ejecutar**:
```bash
python src/data/make_dataset.py
```

---

### 2Ô∏è‚É£ **Construcci√≥n de Features** (`src/features/build_features.py`)

**Entrada**: 
- `data/02_interim/InterimCombinado_*.csv`

**Proceso**:
1. Calcula **generaci√≥n normalizada**: `gen_normalizada = gen_real_mw / potencia_maxima`
2. Crea **features c√≠clicas temporales** (sin/cos):
   - Hora del d√≠a (0-23)
   - Mes del a√±o (1-12)
   - D√≠a del a√±o (1-365)

**Salida**: 
- `data/03_processed/DatosCombinados_*.csv`

**Columnas finales** (13 features totales):
- `gen_normalizada` (target)
- `glb, dni, dif` (radiaci√≥n - 3 features no redundantes)
  - ‚ùå Eliminadas: `ghi` (redundante con `glb`), `dir`, `dirh` (redundantes con `dni`), `difh` (redundante con `dif`), `sct` (baja correlaci√≥n)
- `temp, vel` (temperatura y viento)
- `shadow, cloud` (sombra y nubosidad)
- `hora_sin, hora_cos, mes_sin, mes_cos, dia_a√±o_sin, dia_a√±o_cos` (tiempo c√≠clico)

**Ejecutar**:
```bash
python src/features/build_features.py
```

---

### 3Ô∏è‚É£ **Entrenamiento del Modelo** 

#### **Opci√≥n A: Dual-Stream (Modelo Base)** - `src/models/train_model.py`

**Entrada**: 
- `data/03_processed/DatosCombinados_*.csv`

**Proceso**:
1. **Creaci√≥n de ventanas** (windowing configurable):
   - Hist√≥rico: `in_steps` pasos pasados √ó 13 features (default: 24h)
   - Futuro: 48 pasos futuros √ó 12 features (sin `gen_normalizada`)
   - Target: 48 valores futuros de `gen_normalizada`
   - **Optimizaci√≥n**: Ventana hist√≥rica optimizable (4h-24h seg√∫n planta)

2. **Divisi√≥n cronol√≥gica CON GAPS** (evita data leakage):
   - Train: 70% del dataset
   - Gap: `window_size - 1` registros (evita solapamiento)
   - Validaci√≥n: 15% del dataset
   - Gap: `window_size - 1` registros (evita solapamiento)
   - Test: 15% del dataset
   - ‚úÖ Garant√≠a: Sin informaci√≥n futura en entrenamiento

3. **Arquitectura del modelo Dual-Stream**:
   ```
   Rama 1 (Hist√≥rico - configurable):
   Input(in_steps, 13) ‚Üí BiLSTM(64) ‚Üí BiLSTM(32) ‚Üí Dropout(0.1)
   
   Rama 2 (Pron√≥stico - 48h futuras):
   Input(48, 12) ‚Üí Conv1D(32, kernel=3) ‚Üí Flatten ‚Üí Dense(32)
   
   Fusi√≥n:
   Concatenate ‚Üí Dense(64) ‚Üí Dropout(0.1) ‚Üí Dense(48)
   ```
   - Features reducidas: 13 totales (8 eliminadas por redundancia)
   - Output: 48 valores (horizonte CEN)

4. **Entrenamiento**:
   - Optimizador: Adam (lr=0.001)
   - Loss: MSE
   - M√©trica: MAE
   - EarlyStopping: patience=15
   - Batch size: 32
   - Epochs: 100 (con early stopping)

**Salida**: 
- `models/dual_stream_lstm_cnn_{ID}_{in_steps}h_{out_steps}h.keras`

**Ejecutar**:
```bash
python src/models/train_model.py
```

---

#### **Opci√≥n B: Tri-Stream con Gating** - `src/models/train_alternativo.py`

**Arquitectura avanzada** que modela expl√≠citamente el **estado operativo de la planta** mediante un mecanismo de gating multiplicativo.

**Proceso adicional**:
1. **Tres streams de entrada**:
   - **Rama 1 (Inercia)**: BiLSTM procesa hist√≥rico (misma que Dual-Stream)
   - **Rama 2 (Pron√≥stico Meteorol√≥gico)**: CNN 1D procesa features continuas futuras
   - **Rama 3 (Gating) [NUEVA]**: Red densa procesa variables de estado binarias

2. **Arquitectura Tri-Stream**:
   ```
   Rama 1 (Hist√≥rico):
   Input(in_steps, 13) ‚Üí BiLSTM(64) ‚Üí BiLSTM(32) ‚Üí Dropout(0.1)
   
   Rama 2 (Pron√≥stico Continuo):
   Input(48, 12) ‚Üí Conv1D(32, kernel=3) ‚Üí Flatten ‚Üí Dense(32)
   
   Rama 3 (Gating Binario) [NUEVA]:
   Input(48, 1) ‚Üí Flatten ‚Üí Dense(32) ‚Üí Dense(48, sigmoid, bias_init=3.0)
   
   Fusi√≥n:
   Rama1 + Rama2 ‚Üí Concatenate ‚Üí Dense(64) ‚Üí Dropout(0.1)
                ‚Üí Y_potential (generaci√≥n potencial)
   
   Multiplicaci√≥n Final:
   Y_final = Y_potential ‚äó Y_gate (elemento a elemento)
   ```

3. **Variables de estado (Rama 3)**:
   - **`feriado`**: Indica d√≠as festivos/mantenimiento (0=operando, 1=inactivo)
   - Modula la salida: si `gate ‚âà 0` ‚Üí generaci√≥n se anula (planta no operativa)

4. **Ventajas del Tri-Stream**:
   - ‚úÖ Modela expl√≠citamente interrupciones operativas (feriados, mantenimientos)
   - ‚úÖ Separa generaci√≥n potencial de restricciones operativas
   - ‚úÖ Gate aprende patrones de operaci√≥n autom√°ticamente
   - ‚úÖ Misma configuraci√≥n de hiperpar√°metros que Dual-Stream

**Salida**: 
- `models/tri_stream_gating_{ID}_{in_steps}h_{out_steps}h.keras`

**Ejecutar**:
```bash
python src/models/train_alternativo.py
```

**Comparaci√≥n Dual vs Tri-Stream**:
| Caracter√≠stica | Dual-Stream | Tri-Stream |
|---------------|-------------|------------|
| Inputs | 2 (hist√≥rico + futuro) | 3 (hist√≥rico + futuro + binarias) |
| Modelado de estado | Impl√≠cito | Expl√≠cito (gating) |
| Par√°metros | ~100K | ~105K |
| Complejidad | Media | Alta |
| Casos de uso | General | Plantas con interrupciones frecuentes |

**Salida adicional com√∫n a ambas arquitecturas**:
- `figures/{modelo}_history.csv` (curvas de entrenamiento)
- `figures/training_summary.csv` (resumen comparativo de todos los modelos)

---

### 4Ô∏è‚É£ **Predicci√≥n y Evaluaci√≥n** (`src/models/predict_model.py`)

**Entrada**: 
- `models/dual_stream_lstm_cnn_{ID}_{in_steps}h_{out_steps}h.keras` (o tri_stream_gating_*.keras)
- `data/03_processed/DatosCombinados_*.csv`

**Proceso**:
1. Carga modelo entrenado
2. Genera predicciones en datos de test
3. Calcula m√©tricas: MSE, MAE, RMSE
4. Genera visualizaciones:
   - 5 ejemplos de predicciones vs valores reales
   - Error MAE por hora de predicci√≥n

**Salida**: 
- `figures/predicciones_ejemplos.png`
- `figures/error_por_hora.png`
- M√©tricas en consola

**Ejecutar**:
```bash
python src/models/predict_model.py
```

---

## üöÄ Inicio R√°pido

### 1. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 2. Ejecutar Pipeline Completo

**Opci√≥n A - Script autom√°tico**:
```bash
python run.py
```

**Opci√≥n B - Paso a paso (Dual-Stream)**:
```bash
python src/data/make_dataset.py
python src/features/build_features.py
python src/models/train_model.py
python src/models/predict_model.py
```

**Opci√≥n C - Entrenar modelo Tri-Stream**:
```bash
# Primero asegurar que los datos est√°n procesados
python src/data/make_dataset.py
python src/features/build_features.py

# Entrenar con arquitectura Tri-Stream
python src/models/train_alternativo.py
python src/models/predict_model.py
```

---

## üìä Resultados

### M√©tricas de Evaluaci√≥n (41 Modelos Entrenados)

El sistema ha sido exhaustivamente evaluado con **41 configuraciones diferentes** a trav√©s de 4 plantas, 2 arquitecturas y 2 ventanas hist√≥ricas:

#### **üèÜ Mejores Modelos por Planta (Test MAE)**

| Planta | Modelo | Config | Test MAE | Test MSE | Mejora vs Baseline |
|--------|--------|--------|----------|----------|-------------------|
| **346** | Tri-Stream Gating | 11h‚Üí48h | **0.0224** | 0.0014 | -13% vs Dual-Stream |
| **346** | Tri-Stream Gating | 24h‚Üí48h | **0.0231** | 0.0015 | -11% vs Dual-Stream |
| **239** | Dual-Stream LSTM+CNN | 24h‚Üí48h | **0.0638** | 0.0112 | Baseline |
| **305** | Tri-Stream Gating | 24h‚Üí48h | **0.0454** | 0.0084 | -59% vs Dual-Stream |
| **309** | Dual-Stream LSTM+CNN | 11h‚Üí48h | **0.1438** | 0.0604 | Baseline |

**Interpretaci√≥n MAE**: 
- Planta 346: **2.2% de error promedio** (mejor desempe√±o)
- Planta 239: **6.4% de error promedio** (producci√≥n estable)
- Planta 305: **4.5% de error promedio** (buen desempe√±o)
- Planta 309: **14.4% de error promedio** (requiere optimizaci√≥n)

#### **üìà An√°lisis Comparativo por Arquitectura**

**Dual-Stream (BiLSTM + CNN 1D)** - 23 modelos entrenados:
- ‚úÖ **Estabilidad**: Rendimiento consistente entre plantas
- ‚úÖ **Eficiencia**: R√°pido entrenamiento (4-16 min)
- ‚úÖ **Producci√≥n**: Arquitectura probada y confiable
- üìä **MAE Promedio**: 0.0813 (plantas 239/305/309/346)

**Tri-Stream con Gating** - 18 modelos entrenados:
- ‚úÖ **Precisi√≥n**: Hasta **59% mejor MAE** en planta 305
- ‚úÖ **Interrupciones**: Maneja expl√≠citamente feriados/mantenimientos
- ‚úÖ **Interpretabilidad**: Gate muestra probabilidad operativa
- üìä **MAE Promedio**: 0.0767 (6% mejor que Dual-Stream)
- ‚ö†Ô∏è **Trade-off**: 10-15% m√°s tiempo de entrenamiento

#### **‚è±Ô∏è Eficiencia de Ventanas Hist√≥ricas**

**Hallazgo cr√≠tico**: La ventana hist√≥rica es optimizable sin p√©rdida de precisi√≥n:

| Ventana | Tiempo Entrenamiento | MAE Promedio | Recomendaci√≥n |
|---------|---------------------|--------------|---------------|
| **11h** | 2-6 min (baseline) | 0.0789 | ‚úÖ **√ìptimo para producci√≥n** |
| **24h** | 4-16 min (+167%) | 0.0791 (+0.3%) | ‚ö° Para interpretabilidad |

**Conclusi√≥n**: **11h de hist√≥rico** logra pr√°cticamente el mismo MAE que 24h, con **2.5-3x menos tiempo de entrenamiento**. Recomendado para sistemas de producci√≥n.

### Hallazgos Clave

‚úÖ **41 modelos evaluados**: Benchmark exhaustivo multi-planta, multi-arquitectura, multi-ventana
‚úÖ **Tri-Stream superior**: 6% mejor MAE promedio, hasta 59% mejor en casos espec√≠ficos
‚úÖ **Ventana 11h √≥ptima**: Mismo rendimiento que 24h, 2.5x m√°s r√°pido
‚úÖ **Features reducidas**: 13 features totales (8 redundantes eliminadas) sin p√©rdida de precisi√≥n
‚úÖ **Splits sin solapamiento**: Gaps cronol√≥gicos previenen data leakage
‚úÖ **Multi-planta validado**: Sistema funciona consistentemente en 4 plantas diferentes
‚úÖ **Producci√≥n-ready**: Verbose mode para CI/CD (87.5% reducci√≥n de logs)

### Arquitectura del Modelo

#### Dual-Stream (Producci√≥n)
- **Par√°metros totales**: ~100K (var√≠a con `in_steps`)
- **Tipo**: BiLSTM + CNN 1D Dual-Stream
- **Entradas**: 2 streams (hist√≥rico configurable + pron√≥stico 48h fijo)
- **Salida**: 48 predicciones (horizonte CEN)
- **Casos de uso**: Predicci√≥n general, plantas con operaci√≥n continua

#### Tri-Stream con Gating (Avanzado)
- **Par√°metros totales**: ~105K (var√≠a con `in_steps`)
- **Tipo**: BiLSTM + CNN 1D + Gating Multiplicativo
- **Entradas**: 3 streams (hist√≥rico + pron√≥stico continuo + estado binario)
- **Salida**: 48 predicciones moduladas por gate operativo
- **Innovaci√≥n**: Modelado expl√≠cito de estado operativo de la planta
- **Casos de uso**: Plantas con interrupciones frecuentes, an√°lisis de disponibilidad

### Visualizaciones

Los gr√°ficos generados se encuentran en `figures/`:

1. **training_summary.csv**: Resumen comparativo de los 41 modelos entrenados
2. **{modelo}_history.csv**: Curvas de entrenamiento (loss/MAE) para cada modelo
3. **predicciones_ejemplos.png**: Casos de predicci√≥n vs valores reales (48h horizon)
4. **error_por_hora.png**: Distribuci√≥n del error MAE por cada hora de predicci√≥n (1-48h)
5. **training_history.png**: Curvas de loss y MAE durante entrenamiento

### Notebooks de An√°lisis (Refactorizados)

**`notebooks/exploracion_resultados.ipynb`** - An√°lisis comparativo completo:
- Rankings por planta (Top 5 modelos)
- Visualizaciones: MAE por arquitectura, scatter eficiencia (tiempo vs precisi√≥n)
- Heatmaps: MAE promedio (Planta √ó Arquitectura √ó Ventana)
- Estad√≠sticas resumen: Mejor modelo overall, por arquitectura

---

## üõ†Ô∏è Configuraci√≥n

### Par√°metros Principales (Multi-Planta)

En cada script encontrar√°s esta secci√≥n configurable para trabajar con diferentes plantas:

```python
# Configuraci√≥n por planta (debe ser consistente en todos los scripts)
ID_PLANTA = 239              # Planta a procesar
FECHA_INICIO = '2013-08-08'  # Inicio del per√≠odo de datos disponibles
FECHA_FIN = '2015-08-08'     # Fin del per√≠odo de datos disponibles
```

**Plantas validadas con datos completos:**
- **239**: SDGX01 (1.28 MW) - Datos: 2013-08-08 a 2015-08-08
- **305**: Lalackama II (0.79 MW) - Datos: 2013-08-08 a 2015-08-08
- **309**: Tambo Real (2.94 MW) - Datos: 2013-01-01 a 2015-01-01
- **346**: Esperanza (2.88 MW) - Datos: 2014-01-01 a 2015-12-20

**Importante**: `FECHA_INICIO` y `FECHA_FIN` deben coincidir exactamente con los nombres de archivos en `data/01_raw/`

### Ventanas Temporales (Optimizables)

**Configuraci√≥n est√°ndar**:
- **in_steps**: 11h (√≥ptimo - equilibrio precisi√≥n/eficiencia) o 24h (interpretabilidad)
- **out_steps**: 48 horas fijas (requerimiento CEN - day-ahead + intraday)

Modificable en `train_model.py` y `predict_model.py`:
```python
train_and_evaluate_model(
    in_steps=11,   # Ventana hist√≥rica √≥ptima (tambi√©n 24h disponible)
    out_steps=48   # Ventana de predicci√≥n (FIJO - requerimiento CEN)
)
```

**Resultados de optimizaci√≥n de ventana hist√≥rica (41 modelos evaluados)**:
- **11h input**: √ìptimo - Mismo MAE que 24h, 2.5x m√°s r√°pido de entrenar ‚úÖ **RECOMENDADO**
- **24h input**: Est√°ndar - Captura ciclo diario completo, mejor para interpretabilidad
- **Trade-off**: 11h vs 24h ‚Üí +0.3% MAE, -60% tiempo entrenamiento

**Evidencia emp√≠rica** (MAE Test promedio sobre 41 modelos):
- 11h ‚Üí 48h: MAE = 0.0789 (2-6 min entrenamiento)
- 24h ‚Üí 48h: MAE = 0.0791 (4-16 min entrenamiento)
- **Diferencia**: <0.3% error, >2.5x m√°s r√°pido con 11h

---

## üì¶ Dependencias

**Requisitos del sistema**:
- **Python**: 3.13+ (compatible con 3.10+)
- **TensorFlow**: 2.20+ (backend Keras)
- **Entorno**: Windows/Linux/macOS

**Librer√≠as principales**:
- **pandas** (2.2.3+): Procesamiento de datos y series temporales
- **numpy** (2.1.3+): Operaciones num√©ricas y √°lgebra lineal
- **tensorflow** (2.20+): Deep Learning (modelos BiLSTM + CNN)
- **scikit-learn** (1.6.0+): Normalizaci√≥n (MinMaxScaler) y m√©tricas
- **matplotlib** (3.9.2+): Visualizaciones y gr√°ficos de resultados

**Instalaci√≥n completa**:
```bash
pip install -r requirements.txt
```

Ver `requirements.txt` para versiones exactas y dependencias adicionales (seaborn, scipy, etc.).

---

## üìù Notas Adicionales

### Scripts de Utilidad

**`validar_splits.py`**: Valida que no hay solapamiento temporal en los splits
```bash
python validar_splits.py
```
‚úÖ Verifica que los gaps entre train/val/test evitan data leakage
‚úÖ Muestra rangos de fechas y tama√±o de cada split
‚úÖ Confirma separaci√≥n cronol√≥gica completa

**`verificar_datos.py`**: Verifica integridad de datos crudos
```bash
python verificar_datos.py
```
‚úÖ Valida que los archivos JSON y CSV existen para cada planta
‚úÖ Confirma rangos de fechas correctos
‚úÖ Detecta datos faltantes o inconsistencias

### Archivo extract.py (Opcional)

El archivo `src/data/extract.py` contiene funciones para descargar datos desde la **API del CEN** (Coordinador El√©ctrico Nacional). 

‚ö†Ô∏è **No es necesario ejecutarlo** si ya tienes los datos en `data/01_raw/`.

Para descargar nuevos datos:
```python
from src.data.extract import consultar_generacion_solar
data = consultar_generacion_solar(
    start_date='2013-08-08',
    end_date='2015-08-08',
    id_central=239
)
```

**Nota**: Requiere variable de entorno `CEN_API_KEY` configurada.

### Archivos Intermedios Generados

El sistema genera archivos intermedios para cada planta con nomenclatura estandarizada:
- **Interim**: `InterimCombinado_{FECHA_INICIO}_a_{FECHA_FIN}_Planta{ID}.csv`
- **Processed**: `DatosCombinados_{FECHA_INICIO}_a_{FECHA_FIN}_Planta{ID}.csv`
- **Modelos Dual-Stream**: `dual_stream_lstm_cnn_{ID}_{in_steps}h_{out_steps}h.keras`
- **Modelos Tri-Stream**: `tri_stream_gating_{ID}_{in_steps}h_{out_steps}h.keras`
- **Historial**: `{model_name}_history.csv`

Esto permite:
‚úÖ Trabajar con m√∫ltiples plantas simult√°neamente
‚úÖ Comparar diferentes configuraciones (11h vs 24h)
‚úÖ Mantener trazabilidad completa de experimentos
‚úÖ Reproducir cualquier configuraci√≥n de entrenamiento

### Verbose Mode (Producci√≥n)

**Refactorizaci√≥n Diciembre 2024**: Todos los scripts principales soportan el par√°metro `verbose`:

```python
# Modo producci√≥n (silencioso - default)
train_and_evaluate_model(input_path, output_path, model_name)
# Output: üöÄ Entrenando... ‚Üí ‚úÖ Completado (3 l√≠neas)

# Modo debugging (detallado)
train_and_evaluate_model(input_path, output_path, model_name, verbose=True)
# Output: Carga, splits, shapes, progreso, m√©tricas... (30+ l√≠neas)
```

**Scripts con verbose mode**:
- `src/data/make_dataset.py`
- `src/models/train_model.py`
- `src/models/train_alternativo.py`
- `src/models/predict_model.py`
- `src/models/windowing_utils.py`

**Beneficios**:
- ‚úÖ CI/CD friendly: Logs m√≠nimos en producci√≥n (87.5% reducci√≥n)
- ‚úÖ Debugging habilitado: `verbose=True` cuando se necesita
- ‚úÖ Retrocompatible: Default `False` mantiene API estable

Ver `docs/REFACTORING_SUMMARY.md` para reporte completo.

### Optimizaci√≥n de Features

**Features eliminadas por redundancia (correlaci√≥n > 0.99):**
- `ghi` ‚âà `glb` (radiaci√≥n global - r=0.997)
- `dir`, `dirh` ‚âà `dni` (radiaci√≥n directa - r>0.99)
- `difh` ‚âà `dif` (radiaci√≥n difusa - r=0.998)
- `sct` (baja correlaci√≥n con generaci√≥n)

**Resultado**: **13 features totales** (reducci√≥n de 19‚Üí13, -31%) sin p√©rdida de precisi√≥n.

**Features finales optimizadas**:
1. **Radiaci√≥n** (3): `glb`, `dni`, `dif`
2. **Meteorolog√≠a** (4): `temp`, `vel`, `shadow`, `cloud`
3. **Tiempo c√≠clico** (6): `hora_sin/cos`, `mes_sin/cos`, `dia_a√±o_sin/cos`
4. **Target** (1): `gen_normalizada`

**Validaci√≥n**: 41 modelos entrenados confirman que las 13 features mantienen toda la capacidad predictiva.

### Divisi√≥n de Datos Sin Solapamiento

La divisi√≥n es **cronol√≥gica con gaps** (no aleatoria) para prevenir data leakage:
- **Train**: Primeros 70% del dataset
- **Gap 1**: `window_size - 1` registros descartados (evita solapamiento)
- **Validaci√≥n**: Siguientes 15% del dataset
- **Gap 2**: `window_size - 1` registros descartados (evita solapamiento)
- **Test**: √öltimos 15% del dataset

**Justificaci√≥n de gaps**: Sin gaps, la √∫ltima ventana de train podr√≠a incluir datos que aparecen en la primera ventana de validaci√≥n, causando data leakage. Los gaps garantizan separaci√≥n temporal completa.

**Validaci√≥n**: Usar `validar_splits.py` para verificar que no hay solapamiento en las ventanas.

---

## üéì Metodolog√≠a

### Arquitectura Dual-Stream

El modelo base usa dos ramas especializadas:

1. **Rama BiLSTM** (Hist√≥rico - configurable 4-24h):
   - Captura la **inercia del sistema** y patrones de generaci√≥n pasada
   - √ötil para: tendencias, estacionalidad, comportamiento din√°mico
   - Se adapta autom√°ticamente a diferentes plantas y capacidades
   - **Optimizable**: 4h suficiente para predicci√≥n, 24h mejor para interpretabilidad

2. **Rama CNN 1D** (Pron√≥stico - 48h fijo):
   - Procesa **variables meteorol√≥gicas futuras conocidas** (48h horizon)
   - √ötil para: capturar patrones locales en el pron√≥stico meteorol√≥gico
   - Horizonte de 48h cumple con requerimientos del CEN para declaraci√≥n de disponibilidad

La **fusi√≥n** de ambas ramas permite combinar:
- Conocimiento del comportamiento hist√≥rico de la planta espec√≠fica
- Informaci√≥n del pron√≥stico meteorol√≥gico de largo plazo (48h)

---

### Arquitectura Tri-Stream con Gating Multiplicativo

Extensi√≥n avanzada del Dual-Stream que modela **expl√≠citamente el estado operativo** de la planta:

**Concepto clave**: La generaci√≥n real es el producto de:
```
Generaci√≥n_Real = Generaci√≥n_Potencial √ó Probabilidad_Operativa
```

**Componentes**:

1. **Rama 1 + Rama 2** (Generaci√≥n Potencial):
   - Combinan hist√≥rico (BiLSTM) + pron√≥stico meteorol√≥gico (CNN)
   - Predicen la generaci√≥n **si la planta estuviera operando normalmente**

2. **Rama 3 - Gating [NUEVA]** (Probabilidad Operativa):
   - Procesa variables de **estado binario** (feriados, mantenimientos, desconexiones)
   - Red densa ‚Üí sigmoid (salida 0-1 por cada hora futura)
   - Bias inicializado en +3.0 (gate empieza "abierto" ‚âà0.95)

3. **Multiplicaci√≥n Final**:
   - `Y_final = Y_potential ‚äó Y_gate` (elemento a elemento)
   - Si `gate=1`: planta operando ‚Üí salida = potencial completo
   - Si `gate=0`: planta inactiva ‚Üí salida forzada a 0
   - Valores intermedios: operaci√≥n degradada o parcial

**Ventajas sobre Dual-Stream**:
- ‚úÖ Aprende autom√°ticamente patrones de inactividad
- ‚úÖ Separaci√≥n clara: capacidad f√≠sica vs restricciones operativas
- ‚úÖ Mejor manejo de interrupciones frecuentes (feriados, mantenimientos)
- ‚úÖ Interpretabilidad: gate muestra probabilidad de operaci√≥n por hora

**Cu√°ndo usar cada arquitectura**:
- **Dual-Stream**: Plantas con operaci√≥n continua, predicci√≥n general
- **Tri-Stream**: Plantas con interrupciones frecuentes, an√°lisis de disponibilidad

### Dise√±o Multi-Planta

El sistema es completamente **automatizable** para diferentes plantas:
- **Normalizaci√≥n autom√°tica**: Cada planta se normaliza por su potencia m√°xima
- **Adaptaci√≥n geogr√°fica**: Aprende patrones meteorol√≥gicos espec√≠ficos de cada ubicaci√≥n
- **Escalabilidad temporal**: Funciona con diferentes per√≠odos de datos hist√≥ricos
- **Modelo por planta**: Cada planta entrena su propio modelo optimizado
- **Features optimizadas**: 13 features (8 redundantes eliminadas) mantienen precisi√≥n
- **Escalabilidad temporal**: Funciona con diferentes per√≠odos de datos hist√≥ricos
- **Modelo por planta**: Cada planta entrena su propio modelo optimizado

### Justificaci√≥n: Variable Input ‚Üí 48h Output

**¬øPor qu√© 48 horas de predicci√≥n? (FIJO)**
- **Requerimiento del CEN**: Declaraci√≥n de disponibilidad con 48h de anticipaci√≥n
- **Day-ahead + Intraday**: Cubre mercado del d√≠a siguiente y ajustes intradiarios
- **Planificaci√≥n operativa**: Permite mejor coordinaci√≥n con el sistema el√©ctrico

**¬øPor qu√© ventana hist√≥rica optimizable? (11h-24h)**
- **Hallazgo clave**: 11h de hist√≥rico logra pr√°cticamente mismo MAE que 24h (~0.3% diferencia)
- **Eficiencia**: 11h reduce tiempo de entrenamiento **2.5-3x** vs 24h
- **Trade-off evaluado**: 
  - 11h: Menor tiempo, mismo rendimiento ‚Üí **Producci√≥n**
  - 24h: Contexto diario completo ‚Üí **Interpretabilidad**
- **Recomendaci√≥n**: **11h** para sistemas automatizados, 24h para an√°lisis exploratorio

**Optimizaci√≥n realizada con 41 modelos**:
```
Todas las plantas: 11h vs 24h ‚Üí MAE ~0.0789 vs ~0.0791
                                 Tiempo: 2-6 min vs 4-16 min
Conclusi√≥n: 11h √≥ptimo para producci√≥n (misma precisi√≥n, 2.5x m√°s r√°pido)
```

---

## üìß Contacto y Contribuciones

**Proyecto acad√©mico** - Sistema de predicci√≥n de energ√≠a solar multi-planta con Deep Learning.

### Documentaci√≥n T√©cnica Completa

- **README.md** (este archivo): Gu√≠a general del proyecto
- **`.github/copilot-instructions.md`**: Documentaci√≥n detallada para desarrollo con AI assistants
- **`docs/REFACTORING_SUMMARY.md`**: Reporte de refactorizaci√≥n verbose mode
- **`docs/TRI_STREAM_IMPLEMENTATION.md`**: Documentaci√≥n arquitectura Tri-Stream
- **`figures/training_summary.csv`**: Benchmark completo de 41 modelos

### Reproducibilidad

**Dataset completo en `data/01_raw/`**:
- Generaci√≥n solar: `generacion_solar_*.json` (API CEN)
- Meteorolog√≠a: `Datos2013-2015_Planta*.csv`
- Metadata: `centrales_solares_pre_2017.json`

**Modelos pre-entrenados en `models/`**:
- 23 modelos Dual-Stream (diversas configuraciones)
- 18 modelos Tri-Stream (diversas configuraciones)
- Historial de entrenamiento en `figures/`

**Notebooks ejecutables**:
- EDA completo: `notebooks/exploracion_datos.ipynb`
- Evaluaci√≥n individual: `notebooks/exploracion_modelos.ipynb`
- Benchmark comparativo: `notebooks/exploracion_resultados.ipynb`

### Reconocimientos

- **Coordinador El√©ctrico Nacional (CEN)**: Datos de generaci√≥n solar
- **Dataset meteorol√≥gico**: Datos2013-2015 plantas solares Chile
- **Frameworks**: TensorFlow/Keras, scikit-learn, pandas

---

**Proyecto desarrollado con fines acad√©micos y de investigaci√≥n**. El c√≥digo est√° optimizado para producci√≥n y puede ser adaptado a sistemas operacionales reales con actualizaci√≥n de datos.
### Notebooks Jupyter (Refactorizados - Reporte T√©cnico)

Los notebooks han sido **refactorizados para calidad de reporte t√©cnico final**:

#### **`exploracion_datos.ipynb`** (27 ‚Üí 13 celdas)
**Key Visual Insights del Dataset**:
- ‚úÖ **Serie temporal**: Generaci√≥n completa 2 a√±os + zoom con marcado de feriados
- ‚úÖ **Heatmap estacional**: Patr√≥n generaci√≥n por hora/mes (visualiza ciclo diurno/anual)
- ‚úÖ **Correlaci√≥n**: Matriz 8 variables clave (gen, glb, dni, dif, temp, vel, shadow, cloud)
- ‚úÖ **ACF/PACF**: Justificaci√≥n ventana LSTM (autocorrelaci√≥n significativa hasta lag=24h)
- ‚úÖ **Outliers**: Boxplots 4 variables cr√≠ticas para detecci√≥n de anomal√≠as

#### **`exploracion_modelos.ipynb`** (23 ‚Üí 21 celdas)
**Evaluaci√≥n Individual de Modelo**:
- ‚úÖ **Config multi-planta**: Soporte 239/305/309/346, detecci√≥n autom√°tica arquitectura (Dual/Tri-Stream)
- ‚úÖ **M√©tricas test**: MAE/RMSE/MSE con prints concisos y gr√°ficos comparativos
- ‚úÖ **Curvas entrenamiento**: Loss + MAE train/val con marcador best validation epoch
- ‚úÖ **Predicciones 48h**: 3 ejemplos aleatorios con overlay real vs predicho (visualizaci√≥n temporal)
- ‚úÖ **An√°lisis residuales**: Histograma + Q-Q plot (validaci√≥n normalidad de errores)

#### **`exploracion_resultados.ipynb`** (20 celdas - NUEVO)
**An√°lisis Comparativo Multi-Modelo** (41 modelos entrenados):
- ‚úÖ **Rankings por planta**: Top 5 modelos para cada planta (239/305/309/346)
- ‚úÖ **Comparaci√≥n arquitecturas**: Dual-Stream original/Nuevo + Tri-Stream (23 vs 18 modelos)
- ‚úÖ **An√°lisis eficiencia**: Scatter tiempo vs MAE (identifica configuraciones √≥ptimas)
- ‚úÖ **Distribuciones estad√≠sticas**: Boxplots MAE por arquitectura y ventana hist√≥rica (11h/24h)
- ‚úÖ **Heatmap global**: MAE promedio cruzando (Planta √ó Arquitectura √ó Ventana) - 16 configuraciones
- ‚úÖ **Estad√≠sticas resumen**: Mejor modelo overall, por arquitectura, top 5 general

**Principio de refactorizaci√≥n aplicado**:
- ‚ùå **Eliminados**: Sanity checks repetitivos (df.head(), df.shape), c√≥digo fallido, textos redundantes
- ‚úÖ **Retenidos**: Solo visualizaciones clave con insights accionables
- ‚úÖ **A√±adidos**: Markdown explicativo conciso, interpretaci√≥n de resultados
- üéØ **Resultado**: Notebooks ejecutables de principio a fin, listos para presentaci√≥n t√©cnica
**Archivos clave del proyecto:**
1. **`run.py`**: Punto de entrada del pipeline completo (orquestador)
2. **`src/models/windowing_utils.py`**: L√≥gica de windowing y definici√≥n de 13 features
3. **`src/models/train_model.py`**: Arquitectura Dual-Stream y entrenamiento
4. **`src/models/train_alternativo.py`**: Arquitectura Tri-Stream con Gating
5. **`notebooks/exploracion_datos.ipynb`**: EDA refactorizado (key insights visuales)
6. **`notebooks/exploracion_modelos.ipynb`**: Evaluaci√≥n individual (m√©tricas + visualizaciones)
7. **`notebooks/exploracion_resultados.ipynb`**: Comparaci√≥n multi-modelo (41 modelos, rankings, heatmaps)
8. **`.github/copilot-instructions.md`**: Documentaci√≥n detallada para AI coding assistants
9. **`figures/training_summary.csv`**: Resumen de los 41 modelos entrenados
10. **`docs/REFACTORING_SUMMARY.md`**: Reporte de refactorizaci√≥n verbose mode (87.5% reducci√≥n logs)

---

## üèÜ Conclusiones y Recomendaciones

### Para Producci√≥n

**Configuraci√≥n recomendada**:
- **Arquitectura**: Tri-Stream Gating (6% mejor MAE promedio, maneja interrupciones)
- **Ventana hist√≥rica**: **11h** (mismo rendimiento, 2.5x m√°s r√°pido)
- **Ventana predicci√≥n**: 48h (requerimiento CEN)
- **Features**: 13 optimizadas (radiaci√≥n: 3, meteo: 4, tiempo: 6)
- **Verbose mode**: `False` para CI/CD (logs m√≠nimos)

**Benchmark validado**:
- 41 modelos evaluados exhaustivamente
- 4 plantas con diferentes caracter√≠sticas operativas
- 2 arquitecturas complementarias (Dual/Tri-Stream)
- 2 ventanas hist√≥ricas optimizadas (11h/24h)

### Para Investigaci√≥n

**Oportunidades de mejora**:
1. **Planta 309**: MAE m√°s alto (~14%), requiere an√°lisis espec√≠fico de datos
2. **Ensemble models**: Combinar Dual + Tri-Stream para mayor robustez
3. **Transfer learning**: Aprovechar modelos pre-entrenados entre plantas similares
4. **Atenci√≥n temporal**: Mecanismos de atenci√≥n para mejorar horizonte largo (>24h)
5. **Datos ex√≥genos**: Incorporar pron√≥sticos meteorol√≥gicos de alta resoluci√≥n

### Limitaciones Conocidas

- **Normalizaci√≥n no guardada**: MinMaxScaler aplicado en `make_dataset.py` debe replicarse manualmente para inferencia
- **Datos 2013-2015**: Dataset hist√≥rico, requiere actualizaci√≥n para producci√≥n actual
- **Modelo por planta**: No hay transferencia entre plantas (cada planta entrena su propio modelo)
- **Features binarias**: Solo `feriado` implementado en Tri-Stream, otras variables operativas pendientes

### Nota sobre Desarrollo con IA

**Este proyecto fue desarrollado con asistencia de Inteligencia Artificial**:
- ü§ñ **Claude 3.5 Sonnet** (Anthropic): Desarrollo principal, refactorizaci√≥n de c√≥digo, documentaci√≥n t√©cnica
- ü§ñ **Gemini 2.0 Flash** (Google): An√°lisis de datos, optimizaci√≥n de modelos, generaci√≥n de visualizaciones

El uso de IA permiti√≥:
- ‚úÖ Iteraci√≥n r√°pida de arquitecturas (Dual-Stream ‚Üí Tri-Stream)
- ‚úÖ Refactorizaci√≥n completa del c√≥digo (verbose mode, producci√≥n-ready)
- ‚úÖ Documentaci√≥n exhaustiva (README, notebooks, copilot-instructions)
- ‚úÖ Benchmark extensivo (41 modelos evaluados sistem√°ticamente)

La supervisi√≥n humana asegur√≥ la validez metodol√≥gica, interpretaci√≥n correcta de resultados y decisiones de dise√±o.

---

**√öltima actualizaci√≥n**: Diciembre 12, 2025 - Actualizaci√≥n final con resultados completos (41 modelos)
