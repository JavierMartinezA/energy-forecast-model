import pandas as pd
import numpy as np
import os
import sys
import time
from pathlib import Path

# Imports de TensorFlow/Keras
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Bidirectional, Conv1D, Flatten, Dense, Concatenate, Dropout, Multiply
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.initializers import Constant

# Agregar el directorio ra√≠z al path de Python
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

# --- IMPORTAMOS LAS UTILIDADES ---
# Estas funciones est√°n definidas en src/models/windowing_utils.py
from src.models.windowing_utils import create_dual_stream_data, create_tri_stream_data_alternativo
from src.config import get_plant_config
from src.config import get_plant_config 


# --- 1. FUNCI√ìN DE DEFINICI√ìN DE ARQUITECTURA ---

def build_dual_stream_model(past_shape: tuple, future_shape: tuple, output_steps: int):
    """
    Define y compila el modelo BiLSTM + CNN 1D Dual-Stream para la predicci√≥n.
    """
    
    # Rama 1: Procesamiento del Hist√≥rico (Inercia del sistema)
    # Ejemplo: (24, 19)
    input_past = Input(shape=past_shape, name='Input_Historico')
    x1 = Bidirectional(LSTM(64, return_sequences=True))(input_past)
    x1 = Bidirectional(LSTM(32, return_sequences=False))(x1)
    x1 = Dropout(0.1)(x1) 

    # Rama 2: Procesamiento del Futuro (Pron√≥stico Meteorol√≥gico)
    # Ejemplo: (24, 18)
    input_fut = Input(shape=future_shape, name='Input_Pronostico')
    x2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_fut)
    x2 = Flatten()(x2)
    x2 = Dense(32, activation='relu')(x2)

    # Fusi√≥n de ambas ramas
    combined = Concatenate()([x1, x2])
    z = Dense(64, activation='relu')(combined)
    z = Dropout(0.1)(z)

    # Capa de Salida: output_steps neuronas para predecir todos los pasos futuros
    output = Dense(output_steps, activation='linear', name='Output_Future')(z)

    # Compilar el modelo
    model = Model(inputs=[input_past, input_fut], outputs=output)
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])

    return model


def build_tri_stream_model(past_shape: tuple, future_shape: tuple, binary_shape: tuple, output_steps: int = 48):
    """
    Define y compila el modelo Tri-Stream con Gating Multiplicativo.
    
    Arquitectura:
    - Rama 1 (Inercia): BiLSTM captura din√°mica hist√≥rica
    - Rama 2 (Pron√≥stico): Conv1D extrae patrones meteorol√≥gicos futuros
    - Rama 3 (Gating): Red densa procesa variables binarias para generar probabilidad de operaci√≥n
    
    Fusi√≥n: Y_final = Y_potencial ‚äó Y_gate (multiplicaci√≥n elemento a elemento)
    
    Args:
        past_shape: Shape del input hist√≥rico, ej. (24, 19)
        future_shape: Shape del input futuro continuo, ej. (48, 18)
        binary_shape: Shape del input binario futuro, ej. (48, N_binarias)
        output_steps: N√∫mero de pasos a predecir (default: 48)
    
    Returns:
        model: Modelo Keras compilado
    """
    
    # ========== RAMA 1: PROCESAMIENTO DEL HIST√ìRICO (Inercia del Sistema) ==========
    # Captura la din√°mica reciente y el estado operativo del sistema
    input_past = Input(shape=past_shape, name='Input_Historico')
    x1 = Bidirectional(LSTM(64, return_sequences=True))(input_past)
    x1 = Bidirectional(LSTM(32, return_sequences=False))(x1)
    x1 = Dropout(0.1)(x1)
    
    # ========== RAMA 2: PROCESAMIENTO DEL PRON√ìSTICO METEOROL√ìGICO ==========
    # Extrae patrones locales de radiaci√≥n y condiciones futuras
    input_fut = Input(shape=future_shape, name='Input_Pronostico')
    x2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_fut)
    x2 = Flatten()(x2)
    x2 = Dense(32, activation='relu')(x2)
    
    # ========== RAMA 3: GATING (Variables Binarias/Estado Operativo) [NUEVA] ==========
    # Procesa variables ex√≥genas binarias (ej: is_holiday, maintenance_flag, grid_status)
    # para generar un vector de probabilidad de operaci√≥n [0, 1] para cada hora
    input_binary = Input(shape=binary_shape, name='Input_Binary')
    x3 = Flatten()(input_binary)
    x3 = Dense(32, activation='relu')(x3)
    
    # CR√çTICO: Capa de salida con sigmoid para generar gate [0, 1]
    # Inicializamos el bias con valor positivo (3.0) para empezar con "compuerta abierta"
    # Esto evita gradientes nulos al inicio del entrenamiento
    output_gate = Dense(
        output_steps, 
        activation='sigmoid', 
        name='Output_Gate',
        bias_initializer=Constant(value=3.0)  # Gate empieza cerca de 1 (œÉ(3) ‚âà 0.95)
    )(x3)
    
    # ========== FUSI√ìN: GENERACI√ìN POTENCIAL ==========
    # Combinamos inercia hist√≥rica + pron√≥stico meteorol√≥gico para estimar generaci√≥n potencial
    combined = Concatenate()([x1, x2])
    z = Dense(64, activation='relu')(combined)
    z = Dropout(0.1)(z)
    
    # Generaci√≥n potencial (sin restricciones operativas)
    output_potential = Dense(output_steps, activation='linear', name='Output_Potential')(z)
    
    # ========== MULTIPLICACI√ìN FINAL: Y_final = Y_potencial ‚äó Y_gate ==========
    # El gate modula la generaci√≥n potencial seg√∫n el estado operativo
    # Si gate ‚âà 1: sistema operando normalmente (salida ‚âà potencial)
    # Si gate ‚âà 0: sistema inoperativo (salida ‚âà 0)
    # Valores intermedios representan operaci√≥n parcial o degradada
    output_final = Multiply(name='Output_Final')([output_potential, output_gate])
    
    # ========== COMPILACI√ìN ==========
    model = Model(
        inputs=[input_past, input_fut, input_binary], 
        outputs=output_final
    )
    model.compile(
        optimizer=Adam(learning_rate=0.001), 
        loss='mse', 
        metrics=['mae']
    )
    
    return model


# --- 2. FUNCI√ìN PRINCIPAL DE ENTRENAMIENTO (TRI-STREAM) ---

def train_and_evaluate_model(input_path: str, output_path: str, model_name: str, 
                             in_steps: int = 24, out_steps: int = 24,
                             binary_features: list = None, verbose: bool = False):
    """
    Ejecuta el pipeline completo de preparaci√≥n de datos, entrenamiento y evaluaci√≥n
    usando la arquitectura Tri-Stream con Gating Multiplicativo.
    
    Args:
        binary_features: Lista de nombres de columnas binarias para gating.
                        Si es None, usa ['feriado'] por defecto.
                        shadow y cloud se mantienen como features continuas.
        verbose: Si True, muestra informaci√≥n detallada de progreso
    """
    
    if verbose:
        print(f"Cargando datos procesados desde: {input_path}")
    df = pd.read_csv(input_path, index_col=0, parse_dates=True)
    
    if verbose:
        print(f"\nColumnas disponibles: {list(df.columns)}")
        print(f"Total de columnas: {len(df.columns)}")
        print("\nüîç DIVISI√ìN CRONOL√ìGICA SIN SOLAPAMIENTO")
        print("="*60)
    
    total_timesteps = len(df)
    window_size = in_steps + out_steps  # Tama√±o total de cada ventana
    
    # Calcular √≠ndices de corte en el dataset ORIGINAL
    # Dejamos gap = window_size - 1 entre cada split para evitar solapamiento
    train_end_idx = int(total_timesteps * 0.70)
    val_start_idx = train_end_idx + (window_size - 1)  # Gap para evitar solapamiento
    val_end_idx = int(total_timesteps * 0.85)
    test_start_idx = val_end_idx + (window_size - 1)   # Gap para evitar solapamiento
    
    if test_start_idx >= total_timesteps:
        raise ValueError(f"Dataset muy peque√±o. Necesitas al menos {test_start_idx} registros, tienes {total_timesteps}")
    
    if verbose:
        print(f"Dataset total: {total_timesteps} registros")
        print(f"Ventana total por muestra: {window_size}h ({in_steps}h past + {out_steps}h future)")
        print(f"\nRangos temporales (con gaps para evitar solapamiento):")
        print(f"  Train: {df.index[0]} a {df.index[train_end_idx-1]} ({train_end_idx} registros)")
        print(f"  Gap:   {window_size-1} registros (evita solapamiento)")
        print(f"  Val:   {df.index[val_start_idx]} a {df.index[val_end_idx-1]} ({val_end_idx - val_start_idx} registros)")
        print(f"  Gap:   {window_size-1} registros (evita solapamiento)")
        print(f"  Test:  {df.index[test_start_idx]} a {df.index[-1]} ({total_timesteps - test_start_idx} registros)")
        print("="*60 + "\n")
    
    # Dividir el dataframe ANTES de crear ventanas
    df_train = df.iloc[:train_end_idx]
    df_val = df.iloc[val_start_idx:val_end_idx]
    df_test = df.iloc[test_start_idx:]
    
    if verbose:
        print("\nCreando ventanas TRI-STREAM para cada split...")
    
    # Definir features binarias por defecto si no se especifican
    if binary_features is None:
        binary_features = ['feriado']  # Solo feriado para gating
    
    if missing_features:
        raise ValueError(
            f"\n‚ùå ERROR: Features binarias no encontradas: {missing_features}\n"
            f"Columnas disponibles: {list(df.columns)}"
        )
    
    if verbose:
        print(f"Features binarias para gating (Rama 3): {binary_features}")
        print(f"Features continuas (Ramas 1 y 2): Incluyen shadow, cloud y otras meteorol√≥gicas")
    
    X_past_train, X_fut_train, X_bin_train, Y_train = create_tri_stream_data_alternativo(
        df_train, n_past=in_steps, n_future=out_steps, binary_features=binary_features
    )
    
    X_past_val, X_fut_val, X_bin_val, Y_val = create_tri_stream_data_alternativo(
        df_val, n_past=in_steps, n_future=out_steps, binary_features=binary_features
    )
    
    X_past_test, X_fut_test, X_bin_test, Y_test = create_tri_stream_data_alternativo(
        df_test, n_past=in_steps, n_future=out_steps, binary_features=binary_features
    )

    if verbose:
        print(f"Train: {X_past_train.shape[0]} ventanas | Val: {X_past_val.shape[0]} | Test: {X_past_test.shape[0]}")
    
    # Definici√≥n del modelo
    past_shape = X_past_train.shape[1:]
    future_shape = X_fut_train.shape[1:]
    binary_shape = X_bin_train.shape[1:]
    
    model = build_tri_stream_model(past_shape, future_shape, binary_shape, out_steps)
    if verbose:
        model.summary()

    # --- 2.4 ENTRENAMIENTO ---
    early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)

    print("\nIniciando Entrenamiento TRI-STREAM...")
    
    # Medir tiempo de entrenamiento
    start_time = time.time()
    
    history = model.fit(
        x=[X_past_train, X_fut_train, X_bin_train],  # TRES INPUTS
        y=Y_train,
        validation_data=([X_past_val, X_fut_val, X_bin_val], Y_val),
        epochs=100,      
        batch_size=32,    
        callbacks=[early_stop],
        verbose=1
    )
    
    training_time = time.time() - start_time
    total_epochs = len(history.history['loss'])
    avg_time_per_epoch = training_time / total_epochs
    
    print(f"\n‚è± Tiempo total de entrenamiento: {training_time:.2f} segundos ({training_time/60:.2f} minutos)")
    print(f"‚è± Tiempo promedio por √©poca: {avg_time_per_epoch:.2f} segundos")
    print(f"‚è± √âpocas ejecutadas: {total_epochs}")

    # Evaluaci√≥n
    predictions = model.predict([X_past_test, X_fut_test, X_bin_test], verbose=0)
    mse_test = np.mean((Y_test - predictions) ** 2)
    mae_test = np.mean(np.abs(Y_test - predictions))

    # Guardar modelo
    model_full_path = os.path.join(output_path, model_name)
    os.makedirs(output_path, exist_ok=True)
    model.save(model_full_path) 
    print(f"‚úÖ Modelo guardado: {model_full_path}")
    
    # Guardar historial
    base_dir = os.path.dirname(output_path)
    figures_dir = os.path.join(base_dir, 'figures')
    os.makedirs(figures_dir, exist_ok=True)
    
    history_filename = model_name.replace('.keras', '_history.csv')
    history_path = os.path.join(figures_dir, history_filename)
    
    history_df = pd.DataFrame(history.history)
    history_df['epoch'] = range(1, len(history_df) + 1)
    history_df.to_csv(history_path, index=False)
    
    if verbose:
        print(f"‚úÖ Historial guardado: {history_path}")
    
    # Guardar resumen
    summary_path = os.path.join(figures_dir, 'training_summary.csv')
    
    # Obtener mejores m√©tricas
    best_val_loss = min(history.history['val_loss'])
    best_val_mae = min(history.history['val_mae'])
    
    avg_time_per_epoch = training_time / total_epochs
    
    # Crear o actualizar archivo de resumen
    summary_data = {
        'model_name': [model_name],
        'in_steps': [in_steps],
        'out_steps': [out_steps],
        'total_epochs': [total_epochs],
        'training_time_min': [training_time / 60],
        'best_val_loss': [best_val_loss],
        'best_val_mae': [best_val_mae],
        'test_mse': [mse_test],
        'test_mae': [mae_test]
    }
    
    summary_df = pd.DataFrame(summary_data)
    
    if os.path.exists(summary_path):
        existing_summary = pd.read_csv(summary_path)
        summary_df = pd.concat([existing_summary, summary_df], ignore_index=True)
    
    summary_df.to_csv(summary_path, index=False)
    if verbose:
        print(f"‚úÖ Resumen actualizado: {summary_path}")


# --- 3. BLOQUE MAIN (Para ejecuci√≥n directa/prueba) ---

if __name__ == "__main__":
    
    # --- Par√°metros de Configuraci√≥n ---
    ID_PLANTA = 239  # Solo necesitas cambiar esto!
    
    # Obtener configuraci√≥n autom√°tica de la planta
    plant_config = get_plant_config(ID_PLANTA)
    FECHA_INICIO = plant_config['fecha_inicio']
    FECHA_FIN = plant_config['fecha_fin']
    
    in_steps = 11  # Ventana hist√≥rica (horas pasadas)
    out_steps = 48   # Horizonte de predicci√≥n (horas futuras)
    
    # Obtener el directorio base del proyecto
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    # Rutas absolutas
    PROCESSED_DATA_PATH = os.path.join(
        BASE_DIR, 'data', '03_processed', 
        f'DatosCombinados_{FECHA_INICIO}_a_{FECHA_FIN}_Planta{ID_PLANTA}.csv'
    )
    MODELS_OUTPUT_PATH = os.path.join(BASE_DIR, 'models')
    
    # Ejecutar la funci√≥n principal de entrenamiento
    # Arquitectura TRI-STREAM con Gating Multiplicativo
    
    train_and_evaluate_model(
        input_path=PROCESSED_DATA_PATH,
        output_path=MODELS_OUTPUT_PATH,
        in_steps=in_steps,
        out_steps=out_steps,
        model_name=f'tri_stream_gating_{ID_PLANTA}_{in_steps}h_{out_steps}h.keras',
        binary_features=['feriado'],  # Solo feriado para gating (shadow y cloud quedan continuas)
        verbose=True  # Mostrar informaci√≥n detallada en modo directo
    )